# -*- coding: utf-8 -*-
"""Intelligent Log Analytics & Anomaly Detection System

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y1sEyvWd3UiDWmKNrdVAn4E3hqiXSSDK
"""

"""
DevOps Project 5: Intelligent Log Analytics & Anomaly Detection System
An advanced log analysis platform that uses machine learning to detect anomalies,
predict incidents, identify root causes, and provide real-time alerts for
production systems with automated pattern recognition and correlation analysis.
"""

import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import IsolationForest
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
import re
import json
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

class LogAnalyticsSystem:
    def __init__(self):
        self.anomaly_detector = IsolationForest(contamination=0.05, random_state=42)
        self.scaler = StandardScaler()
        self.log_data = None
        self.anomalies = []
        self.patterns = {}
        self.incidents = []
        self.metrics = {}

    def generate_system_logs(self, days=7, logs_per_minute=100):
        """Generate realistic system logs with patterns and anomalies"""
        total_minutes = days * 24 * 60
        total_logs = total_minutes * logs_per_minute

        log_levels = ['INFO', 'WARNING', 'ERROR', 'CRITICAL', 'DEBUG']
        services = ['api-gateway', 'auth-service', 'database', 'cache-redis',
                   'payment-service', 'notification-service', 'analytics-engine']

        error_messages = [
            'Connection timeout to database',
            'Failed to authenticate user',
            'Memory limit exceeded',
            'Disk space running low',
            'API rate limit exceeded',
            'SSL certificate validation failed',
            'Service unavailable',
            'Request timeout after 30s',
            'Database connection pool exhausted',
            'Cache miss ratio high',
            'Payment gateway unreachable',
            'Email delivery failed',
            'CPU usage above threshold',
            'Network latency spike detected',
            'Out of memory error'
        ]

        logs = []
        start_time = datetime.now() - timedelta(days=days)

        for i in range(total_logs):
            timestamp = start_time + timedelta(minutes=i/logs_per_minute)
            hour = timestamp.hour

            # Normal traffic pattern (higher during business hours)
            if 9 <= hour <= 18:
                base_error_rate = 0.02
            elif 18 <= hour <= 23:
                base_error_rate = 0.015
            else:
                base_error_rate = 0.005

            # Inject anomalies
            is_anomaly = False

            # Anomaly 1: Database outage (random occurrence)
            if np.random.random() < 0.0001:  # 0.01% chance
                level = 'CRITICAL'
                service = 'database'
                message = 'Connection timeout to database'
                response_time = np.random.uniform(5000, 10000)
                is_anomaly = True

            # Anomaly 2: Memory leak (gradual increase)
            elif i % 10000 == 0 and i > 0:
                level = 'ERROR'
                service = np.random.choice(services)
                message = 'Memory limit exceeded'
                response_time = np.random.uniform(2000, 5000)
                is_anomaly = True

            # Anomaly 3: API rate limiting
            elif timestamp.minute % 30 == 0 and np.random.random() < 0.001:
                level = 'WARNING'
                service = 'api-gateway'
                message = 'API rate limit exceeded'
                response_time = np.random.uniform(100, 500)
                is_anomaly = True

            # Anomaly 4: Disk space issue
            elif timestamp.hour == 3 and timestamp.minute < 5 and np.random.random() < 0.01:
                level = 'WARNING'
                service = 'analytics-engine'
                message = 'Disk space running low'
                response_time = np.random.uniform(50, 200)
                is_anomaly = True

            # Normal logs
            else:
                if np.random.random() < base_error_rate:
                    level = np.random.choice(['WARNING', 'ERROR'], p=[0.7, 0.3])
                    message = np.random.choice(error_messages)
                else:
                    level = np.random.choice(['INFO', 'DEBUG'], p=[0.8, 0.2])
                    message = 'Request processed successfully'

                service = np.random.choice(services)
                response_time = np.random.lognormal(4, 1)  # Log-normal distribution

            # Calculate metrics
            status_code = 500 if level in ['ERROR', 'CRITICAL'] else (
                404 if np.random.random() < 0.05 else (
                    200 if np.random.random() < 0.95 else 503
                )
            )

            user_id = f"user_{np.random.randint(1, 1000)}"
            request_id = f"req_{i:010d}"

            logs.append({
                'timestamp': timestamp,
                'level': level,
                'service': service,
                'message': message,
                'response_time_ms': round(response_time, 2),
                'status_code': status_code,
                'user_id': user_id,
                'request_id': request_id,
                'is_anomaly': is_anomaly,
                'hour': hour,
                'day_of_week': timestamp.weekday(),
                'minute': timestamp.minute
            })

        self.log_data = pd.DataFrame(logs)
        return self.log_data

    def extract_log_features(self):
        """Extract features from logs for ML analysis"""
        df = self.log_data.copy()

        # Time-based features
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)

        # Encode categorical variables
        df['level_encoded'] = df['level'].map({
            'DEBUG': 0, 'INFO': 1, 'WARNING': 2, 'ERROR': 3, 'CRITICAL': 4
        })

        df['service_encoded'] = pd.factorize(df['service'])[0]

        # Calculate rolling statistics (per service)
        df = df.sort_values('timestamp')
        df['error_rate_5min'] = df.groupby('service')['level'].transform(
            lambda x: (x.isin(['ERROR', 'CRITICAL'])).rolling(5, min_periods=1).mean()
        )

        df['avg_response_time_5min'] = df.groupby('service')['response_time_ms'].transform(
            lambda x: x.rolling(5, min_periods=1).mean()
        )

        # Response time percentiles
        df['response_time_log'] = np.log1p(df['response_time_ms'])

        return df

    def detect_anomalies(self):
        """Use ML to detect anomalous log patterns"""
        print("\nðŸ” Running ML-based Anomaly Detection...")

        df = self.extract_log_features()

        # Select features for anomaly detection
        feature_cols = [
            'level_encoded', 'service_encoded', 'response_time_log',
            'status_code', 'hour_sin', 'hour_cos',
            'error_rate_5min', 'avg_response_time_5min'
        ]

        X = df[feature_cols].fillna(0)

        # Scale features
        X_scaled = self.scaler.fit_transform(X)

        # Detect anomalies
        predictions = self.anomaly_detector.fit_predict(X_scaled)
        df['ml_anomaly'] = predictions == -1

        # Calculate anomaly score
        anomaly_scores = self.anomaly_detector.score_samples(X_scaled)
        df['anomaly_score'] = anomaly_scores

        # Extract anomalies with all necessary columns
        anomalies = df[df['ml_anomaly'] == True].copy()

        # Ensure anomaly_score is in anomalies DataFrame
        if 'anomaly_score' not in anomalies.columns:
            anomalies['anomaly_score'] = df.loc[anomalies.index, 'anomaly_score']

        self.anomalies = anomalies

        print(f"  âœ“ Detected {len(anomalies)} anomalous log entries")
        print(f"  âœ“ Anomaly rate: {(len(anomalies)/len(df))*100:.2f}%")

        # Update log_data with ML predictions
        self.log_data = df

        return anomalies

    def identify_error_patterns(self):
        """Identify recurring error patterns and frequencies"""
        print("\nðŸ“Š Identifying Error Patterns...")

        error_logs = self.log_data[self.log_data['level'].isin(['ERROR', 'CRITICAL'])]

        # Pattern 1: Most common error messages
        error_messages = Counter(error_logs['message'])

        # Pattern 2: Error clustering by service
        error_by_service = error_logs.groupby('service').agg({
            'message': 'count',
            'response_time_ms': 'mean'
        }).rename(columns={'message': 'error_count'})

        # Pattern 3: Time-based patterns
        error_by_hour = error_logs.groupby('hour').size()

        # Pattern 4: Correlated errors (errors happening together)
        time_window = timedelta(minutes=5)
        correlated_errors = []

        for service in error_logs['service'].unique():
            service_errors = error_logs[error_logs['service'] == service].sort_values('timestamp')

            for i in range(len(service_errors) - 1):
                time_diff = (service_errors.iloc[i+1]['timestamp'] -
                           service_errors.iloc[i]['timestamp'])

                if time_diff <= time_window:
                    correlated_errors.append({
                        'service': service,
                        'error1': service_errors.iloc[i]['message'],
                        'error2': service_errors.iloc[i+1]['message'],
                        'time_diff_seconds': time_diff.total_seconds()
                    })

        self.patterns = {
            'top_errors': dict(error_messages.most_common(10)),
            'errors_by_service': error_by_service.to_dict(),
            'errors_by_hour': error_by_hour.to_dict(),
            'correlated_errors': correlated_errors[:20]
        }

        print(f"  âœ“ Found {len(error_messages)} unique error types")
        print(f"  âœ“ Identified {len(correlated_errors)} correlated error pairs")

        return self.patterns

    def predict_incidents(self):
        """Predict potential incidents based on log patterns"""
        print("\nâš ï¸  Predicting Potential Incidents...")

        df = self.log_data.copy()

        # Define incident criteria
        incidents = []

        # Incident 1: High error rate in time window
        for service in df['service'].unique():
            service_logs = df[df['service'] == service].sort_values('timestamp')

            # Calculate 10-minute rolling error rate
            service_logs['error_rate_10min'] = (
                service_logs['level'].isin(['ERROR', 'CRITICAL'])
            ).rolling(10, min_periods=1).mean()

            high_error_periods = service_logs[service_logs['error_rate_10min'] > 0.3]

            if len(high_error_periods) > 0:
                for idx, period in high_error_periods.iterrows():
                    incidents.append({
                        'type': 'High Error Rate',
                        'severity': 'HIGH',
                        'service': service,
                        'timestamp': period['timestamp'],
                        'error_rate': round(period['error_rate_10min'] * 100, 2),
                        'description': f'Error rate exceeded 30% threshold',
                        'recommendation': 'Investigate service logs, check dependencies'
                    })

        # Incident 2: Response time degradation
        for service in df['service'].unique():
            service_logs = df[df['service'] == service].sort_values('timestamp')

            p95_baseline = service_logs['response_time_ms'].quantile(0.95)

            # Check for response time spikes
            service_logs['response_time_spike'] = (
                service_logs['response_time_ms'] > p95_baseline * 2
            )

            spike_periods = service_logs[service_logs['response_time_spike']].groupby(
                pd.Grouper(key='timestamp', freq='10min')
            ).size()

            high_spike_periods = spike_periods[spike_periods > 5]

            for timestamp, count in high_spike_periods.items():
                incidents.append({
                    'type': 'Response Time Degradation',
                    'severity': 'MEDIUM',
                    'service': service,
                    'timestamp': timestamp,
                    'spike_count': int(count),
                    'description': f'Response time exceeded P95 baseline',
                    'recommendation': 'Check system resources, scale if needed'
                })

        # Incident 3: Cascading failures (multiple services failing)
        critical_logs = df[df['level'] == 'CRITICAL'].sort_values('timestamp')

        for i in range(len(critical_logs) - 2):
            time_window = critical_logs.iloc[i:i+3]['timestamp']
            time_span = (time_window.max() - time_window.min()).total_seconds()

            if time_span < 300:  # Within 5 minutes
                affected_services = critical_logs.iloc[i:i+3]['service'].unique()

                if len(affected_services) >= 2:
                    incidents.append({
                        'type': 'Cascading Failure',
                        'severity': 'CRITICAL',
                        'service': ', '.join(affected_services),
                        'timestamp': critical_logs.iloc[i]['timestamp'],
                        'affected_services': len(affected_services),
                        'description': f'Multiple services failing simultaneously',
                        'recommendation': 'IMMEDIATE: Check infrastructure, possible system-wide issue'
                    })

        self.incidents = incidents

        # Remove duplicates
        self.incidents = pd.DataFrame(incidents).drop_duplicates(
            subset=['type', 'service', 'timestamp']
        ).to_dict('records')

        print(f"  âœ“ Predicted {len(self.incidents)} potential incidents")

        severity_counts = Counter([i['severity'] for i in self.incidents])
        for severity, count in severity_counts.items():
            print(f"    â€¢ {severity}: {count}")

        return self.incidents

    def calculate_system_health_score(self):
        """Calculate overall system health score (0-100)"""
        df = self.log_data

        # Metrics
        total_logs = len(df)
        error_count = len(df[df['level'].isin(['ERROR', 'CRITICAL'])])
        error_rate = error_count / total_logs

        avg_response_time = df['response_time_ms'].mean()
        p95_response_time = df['response_time_ms'].quantile(0.95)
        p99_response_time = df['response_time_ms'].quantile(0.99)

        success_rate = len(df[df['status_code'] == 200]) / total_logs

        anomaly_rate = len(self.anomalies) / total_logs if len(self.anomalies) > 0 else 0

        critical_incidents = sum(1 for i in self.incidents if i['severity'] == 'CRITICAL')
        high_incidents = sum(1 for i in self.incidents if i['severity'] == 'HIGH')

        # Health score calculation (weighted factors)
        health_score = 100

        # Penalize error rate
        health_score -= min(30, error_rate * 1000)

        # Penalize slow response times
        if p95_response_time > 1000:
            health_score -= min(20, (p95_response_time - 1000) / 100)

        # Penalize low success rate
        health_score -= (1 - success_rate) * 20

        # Penalize anomalies
        health_score -= min(15, anomaly_rate * 300)

        # Penalize incidents
        health_score -= critical_incidents * 5
        health_score -= high_incidents * 2

        health_score = max(0, min(100, health_score))

        self.metrics = {
            'health_score': round(health_score, 2),
            'total_logs': total_logs,
            'error_rate': round(error_rate * 100, 2),
            'success_rate': round(success_rate * 100, 2),
            'avg_response_time': round(avg_response_time, 2),
            'p95_response_time': round(p95_response_time, 2),
            'p99_response_time': round(p99_response_time, 2),
            'anomaly_count': len(self.anomalies),
            'anomaly_rate': round(anomaly_rate * 100, 2),
            'critical_incidents': critical_incidents,
            'high_incidents': high_incidents,
            'health_status': self._get_health_status(health_score)
        }

        return self.metrics

    def _get_health_status(self, score):
        """Convert health score to status"""
        if score >= 90:
            return 'ðŸŸ¢ EXCELLENT'
        elif score >= 75:
            return 'ðŸŸ¡ GOOD'
        elif score >= 60:
            return 'ðŸŸ  WARNING'
        else:
            return 'ðŸ”´ CRITICAL'

    def generate_report(self):
        """Generate comprehensive log analysis report"""
        print("\n" + "="*80)
        print("ðŸ“Š LOG ANALYTICS & ANOMALY DETECTION REPORT")
        print("="*80)

        # System Health
        print("\nðŸ¥ SYSTEM HEALTH OVERVIEW")
        print("-" * 80)
        print(f"Health Score:                   {self.metrics['health_score']}/100")
        print(f"Status:                         {self.metrics['health_status']}")
        print(f"Total Logs Analyzed:            {self.metrics['total_logs']:,}")
        print(f"Time Period:                    {(self.log_data['timestamp'].max() - self.log_data['timestamp'].min()).days} days")

        # Performance Metrics
        print("\nâš¡ PERFORMANCE METRICS")
        print("-" * 80)
        print(f"Average Response Time:          {self.metrics['avg_response_time']:.2f} ms")
        print(f"P95 Response Time:              {self.metrics['p95_response_time']:.2f} ms")
        print(f"P99 Response Time:              {self.metrics['p99_response_time']:.2f} ms")
        print(f"Success Rate:                   {self.metrics['success_rate']:.2f}%")
        print(f"Error Rate:                     {self.metrics['error_rate']:.2f}%")

        # Anomalies
        print("\nðŸ” ANOMALY DETECTION")
        print("-" * 80)
        print(f"Anomalies Detected:             {self.metrics['anomaly_count']}")
        print(f"Anomaly Rate:                   {self.metrics['anomaly_rate']:.2f}%")

        if len(self.anomalies) > 0:
            print(f"\nðŸ“Œ Top 5 Anomalies:")
            # Check if anomaly_score exists
            if 'anomaly_score' in self.anomalies.columns:
                top_anomalies = self.anomalies.nsmallest(5, 'anomaly_score')
            else:
                # Fallback: just take first 5
                top_anomalies = self.anomalies.head(5)

            for idx, (_, anomaly) in enumerate(top_anomalies.iterrows(), 1):
                print(f"\n  {idx}. {anomaly['level']} - {anomaly['service']}")
                print(f"     Time: {anomaly['timestamp']}")
                print(f"     Message: {anomaly['message']}")
                print(f"     Response Time: {anomaly['response_time_ms']:.2f} ms")
                if 'anomaly_score' in anomaly.index:
                    print(f"     Anomaly Score: {anomaly['anomaly_score']:.4f}")

        # Error Patterns
        print("\nðŸ“Š ERROR PATTERNS")
        print("-" * 80)
        print(f"Unique Error Types:             {len(self.patterns['top_errors'])}")
        print(f"\nTop 5 Most Frequent Errors:")
        for i, (error, count) in enumerate(list(self.patterns['top_errors'].items())[:5], 1):
            print(f"  {i}. {error}: {count} occurrences")

        # Incidents
        print("\nâš ï¸  PREDICTED INCIDENTS")
        print("-" * 80)
        print(f"Total Incidents Predicted:      {len(self.incidents)}")
        print(f"  â€¢ Critical:                   {self.metrics['critical_incidents']}")
        print(f"  â€¢ High:                       {self.metrics['high_incidents']}")

        if len(self.incidents) > 0:
            critical_incidents = [i for i in self.incidents if i['severity'] == 'CRITICAL'][:3]

            if critical_incidents:
                print(f"\nðŸš¨ CRITICAL INCIDENTS (Immediate Action Required):")
                for i, incident in enumerate(critical_incidents, 1):
                    print(f"\n  {i}. {incident['type']}")
                    print(f"     Service: {incident['service']}")
                    print(f"     Time: {incident['timestamp']}")
                    print(f"     Description: {incident['description']}")
                    print(f"     Recommendation: {incident['recommendation']}")

        # Service Health
        print("\nðŸ”§ SERVICE HEALTH BREAKDOWN")
        print("-" * 80)
        service_stats = self.log_data.groupby('service').agg({
            'level': lambda x: (x.isin(['ERROR', 'CRITICAL'])).sum(),
            'response_time_ms': 'mean',
            'status_code': lambda x: (x == 200).sum() / len(x) * 100
        }).rename(columns={
            'level': 'error_count',
            'response_time_ms': 'avg_response_time',
            'status_code': 'success_rate'
        })

        for service, stats in service_stats.iterrows():
            status = 'ðŸŸ¢' if stats['error_count'] < 10 else ('ðŸŸ¡' if stats['error_count'] < 50 else 'ðŸ”´')
            print(f"{status} {service:20} | Errors: {int(stats['error_count']):4} | "
                  f"Avg RT: {stats['avg_response_time']:6.1f}ms | "
                  f"Success: {stats['success_rate']:5.1f}%")

        # Recommendations
        print("\nðŸ’¡ RECOMMENDATIONS")
        print("-" * 80)

        if self.metrics['health_score'] < 60:
            print("ðŸš¨ IMMEDIATE ACTION REQUIRED:")
            print("  â€¢ System health is critical - investigate immediately")
            print("  â€¢ Review all critical and high-severity incidents")
            print("  â€¢ Consider scaling resources or rolling back recent changes")

        if self.metrics['error_rate'] > 5:
            print("\nâš ï¸  HIGH ERROR RATE:")
            print(f"  â€¢ Error rate at {self.metrics['error_rate']:.2f}% (threshold: 5%)")
            print("  â€¢ Review error patterns and fix top recurring errors")

        if self.metrics['p95_response_time'] > 1000:
            print("\nâ±ï¸  PERFORMANCE DEGRADATION:")
            print(f"  â€¢ P95 response time at {self.metrics['p95_response_time']:.0f}ms")
            print("  â€¢ Optimize slow queries or scale infrastructure")

        if len(self.anomalies) > 100:
            print("\nðŸ” HIGH ANOMALY RATE:")
            print(f"  â€¢ {len(self.anomalies)} anomalies detected")
            print("  â€¢ Review anomalous patterns for security threats")

        print(f"\n{'='*80}\n")

    def visualize_analytics(self):
        """Create comprehensive visualization of log analytics"""
        fig = plt.figure(figsize=(20, 14))

        # 1. Logs by Level Over Time
        ax1 = plt.subplot(3, 3, 1)
        log_level_time = self.log_data.groupby([pd.Grouper(key='timestamp', freq='1H'), 'level']).size().unstack(fill_value=0)
        log_level_time.plot(ax=ax1, linewidth=2)
        ax1.set_title('Log Levels Over Time (Hourly)', fontsize=14, fontweight='bold')
        ax1.set_xlabel('Time')
        ax1.set_ylabel('Log Count')
        ax1.legend(title='Level', loc='upper left')
        ax1.grid(True, alpha=0.3)

        # 2. Response Time Distribution
        ax2 = plt.subplot(3, 3, 2)
        ax2.hist(np.log1p(self.log_data['response_time_ms']), bins=50, color='#667eea', alpha=0.7, edgecolor='black')
        ax2.axvline(np.log1p(self.metrics['p95_response_time']), color='red', linestyle='--',
                   linewidth=2, label=f'P95: {self.metrics["p95_response_time"]:.0f}ms')
        ax2.set_title('Response Time Distribution (Log Scale)', fontsize=14, fontweight='bold')
        ax2.set_xlabel('Log(Response Time ms)')
        ax2.set_ylabel('Frequency')
        ax2.legend()
        ax2.grid(True, alpha=0.3)

        # 3. Health Score Gauge
        ax3 = plt.subplot(3, 3, 3)
        theta = np.linspace(0, np.pi, 100)
        radius = 1

        colors_gauge = ['#FF0000', '#FF6B6B', '#FFA500', '#FFD700', '#4ECDC4']
        segments = 5
        for i in range(segments):
            start_angle = i * np.pi / segments
            end_angle = (i + 1) * np.pi / segments
            theta_seg = np.linspace(start_angle, end_angle, 20)
            x_seg = radius * np.cos(theta_seg)
            y_seg = radius * np.sin(theta_seg)
            ax3.fill_between(x_seg, 0, y_seg, color=colors_gauge[4-i], alpha=0.6)

        needle_angle = np.pi * (1 - self.metrics['health_score']/100)
        ax3.plot([0, radius * 0.9 * np.cos(needle_angle)],
                [0, radius * 0.9 * np.sin(needle_angle)],
                'k-', linewidth=3)
        ax3.plot(0, 0, 'ko', markersize=10)

        ax3.set_xlim(-1.2, 1.2)
        ax3.set_ylim(-0.2, 1.2)
        ax3.set_aspect('equal')
        ax3.axis('off')
        ax3.text(0, -0.1, f'{self.metrics["health_score"]:.1f}/100',
                ha='center', fontsize=16, fontweight='bold')
        ax3.text(0, -0.3, 'System Health', ha='center', fontsize=12)
        ax3.set_title('Overall Health Score', fontsize=14, fontweight='bold')

        # 4. Error Rate by Service
        ax4 = plt.subplot(3, 3, 4)
        service_errors = self.log_data[self.log_data['level'].isin(['ERROR', 'CRITICAL'])].groupby('service').size().sort_values()
        service_errors.plot(kind='barh', ax=ax4, color='#f093fb', edgecolor='black')
        ax4.set_title('Error Count by Service', fontsize=14, fontweight='bold')
        ax4.set_xlabel('Error Count')
        ax4.grid(True, alpha=0.3, axis='x')

        # 5. Anomaly Detection Timeline
        ax5 = plt.subplot(3, 3, 5)
        if len(self.anomalies) > 0:
            anomaly_hourly = self.anomalies.groupby(pd.Grouper(key='timestamp', freq='1H')).size()
            anomaly_hourly.plot(ax=ax5, color='#FF6B6B', linewidth=2, marker='o')
            ax5.set_title('Anomalies Detected Over Time', fontsize=14, fontweight='bold')
            ax5.set_xlabel('Time')
            ax5.set_ylabel('Anomaly Count')
            ax5.grid(True, alpha=0.3)

        # 6. Top Errors
        ax6 = plt.subplot(3, 3, 6)
        top_errors = dict(list(self.patterns['top_errors'].items())[:8])
        if top_errors:
            y_pos = np.arange(len(top_errors))
            ax6.barh(y_pos, list(top_errors.values()), color='#45B7D1', edgecolor='black')
            ax6.set_yticks(y_pos)
            ax6.set_yticklabels([k[:30] + '...' if len(k) > 30 else k for k in top_errors.keys()], fontsize=9)
            ax6.set_title('Most Frequent Errors', fontsize=14, fontweight='bold')
            ax6.set_xlabel('Count')
            ax6.grid(True, alpha=0.3, axis='x')

        # 7. Response Time by Service
        ax7 = plt.subplot(3, 3, 7)
        service_rt = self.log_data.groupby('service')['response_time_ms'].mean().sort_values()
        service_rt.plot(kind='barh', ax=ax7, color='#FFD700', edgecolor='black')
        ax7.set_title('Average Response Time by Service', fontsize=14, fontweight='bold')
        ax7.set_xlabel('Response Time (ms)')
        ax7.grid(True, alpha=0.3, axis='x')

        # 8. Incident Severity Distribution
        ax8 = plt.subplot(3, 3, 8)
        if len(self.incidents) > 0:
            incident_severity = pd.Series([i['severity'] for i in self.incidents]).value_counts()
            colors_severity = {'CRITICAL': '#FF0000', 'HIGH': '#FF6B6B', 'MEDIUM': '#FFA500', 'LOW': '#4ECDC4'}
            bars = ax8.bar(incident_severity.index, incident_severity.values,
                          color=[colors_severity.get(s, '#CCCCCC') for s in incident_severity.index],
                          edgecolor='black', linewidth=1.5)
            ax8.set_title('Predicted Incidents by Severity', fontsize=14, fontweight='bold')
            ax8.set_ylabel('Count')
            for bar in bars:
                height = bar.get_height()
                ax8.text(bar.get_x() + bar.get_width()/2., height,
                        f'{int(height)}', ha='center', va='bottom', fontweight='bold')
            ax8.grid(True, alpha=0.3, axis='y')

        # 9. Hourly Log Heatmap
        ax9 = plt.subplot(3, 3, 9)
        pivot_logs = self.log_data.pivot_table(
            values='level_encoded',
            index='day_of_week',
            columns='hour',
            aggfunc='count'
        )
        sns.heatmap(pivot_logs, cmap='YlOrRd', ax=ax9, cbar_kws={'label': 'Log Count'})
        ax9.set_title('Log Activity Heatmap (Day vs Hour)', fontsize=14, fontweight='bold')
        ax9.set_ylabel('Day of Week (0=Mon)')
        ax9.set_xlabel('Hour of Day')

        plt.tight_layout()
        plt.savefig('log_analytics_dashboard.png', dpi=300, bbox_inches='tight')
        print("\nâœ“ Visualization saved as 'log_analytics_dashboard.png'")
        plt.show()

def main():
    print("ðŸ“Š Intelligent Log Analytics & Anomaly Detection System")
    print("=" * 80)

    analyzer = LogAnalyticsSystem()

    # Step 1: Generate system logs
    print("\nðŸ“ Step 1: Generating system logs (7 days, ~100K logs)...")
    logs = analyzer.generate_system_logs(days=7, logs_per_minute=100)
    print(f"âœ“ Generated {len(logs):,} log entries")
    print(f"  â€¢ Services: {logs['service'].nunique()}")
    print(f"  â€¢ Time Range: {logs['timestamp'].min()} to {logs['timestamp'].max()}")

    # Step 2: Extract features
    print("\nðŸ”¬ Step 2: Extracting log features for analysis...")
    featured_logs = analyzer.extract_log_features()
    print(f"âœ“ Extracted features for ML analysis")

    # Step 3: Detect anomalies
    print("\n" + "="*80)
    print("ANOMALY DETECTION PHASE")
    print("="*80)
    anomalies = analyzer.detect_anomalies()

    # Step 4: Identify patterns
    patterns = analyzer.identify_error_patterns()

    # Step 5: Predict incidents
    incidents = analyzer.predict_incidents()

    # Step 6: Calculate health score
    print("\nðŸ¥ Step 6: Calculating system health score...")
    metrics = analyzer.calculate_system_health_score()
    print(f"âœ“ System Health Score: {metrics['health_score']}/100")
    print(f"âœ“ Status: {metrics['health_status']}")

    # Step 7: Generate report
    analyzer.generate_report()

    # Step 8: Visualize
    print("\nðŸ“Š Step 8: Creating analytics visualizations...")
    analyzer.visualize_analytics()

    print("\nâœ… Log analytics complete!")
    print("\nðŸ“ Generated files:")
    print("  - log_analytics_dashboard.png (9-panel analytics dashboard)")

    # Summary
    print(f"\nðŸ“Š EXECUTIVE SUMMARY:")
    print(f"  Logs Analyzed: {len(logs):,}")
    print(f"  Anomalies Found: {len(anomalies)}")
    print(f"  Incidents Predicted: {len(incidents)}")
    print(f"  Health Score: {metrics['health_score']}/100")
    print(f"  Error Rate: {metrics['error_rate']:.2f}%")
    print(f"  P95 Response Time: {metrics['p95_response_time']:.0f}ms")

    if metrics['critical_incidents'] > 0:
        print(f"\nðŸš¨ ALERT: {metrics['critical_incidents']} critical incident(s) detected!")
        print("   Immediate action required - review critical incidents section")
    elif metrics['health_score'] < 70:
        print(f"\nâš ï¸  WARNING: System health below threshold")
        print("   Review error patterns and optimize performance")
    else:
        print(f"\nâœ… System operating within normal parameters")

if __name__ == "__main__":
    main()